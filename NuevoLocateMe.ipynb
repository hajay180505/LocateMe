{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX5fZz3UA7KftvpmOeb2gT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hajay180505/LocateMe/blob/main/NuevoLocateMe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hajay180505/LocateMe.git"
      ],
      "metadata": {
        "id": "qVEBhE51-4n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Imports:\n",
        "> * **csv** - for creating a csv data file from the read data \\\\\n",
        "> * **pandas** - to create a dataframe for the dataset in order to train it\n",
        ">*  **numpy** - for data handling processes\n",
        ">* **train_test_split** - for splitting testing and training data\n",
        ">* **K NeighborsClassifier** - the ML model used"
      ],
      "metadata": {
        "id": "xb_mfed3vdgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "Leh_e6Rcva0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing the data:\n",
        "  The collected data from RPI is parsed to make it into a single csv file."
      ],
      "metadata": {
        "id": "xEbWskKe67lg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "1KSTW9sgPJaA",
        "outputId": "103a80ea-d57a-4e92-f289-c54c151a43d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9391634980988594\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport csv\\nfile_paths = [\"201.txt\"]\\n#data = []\\nfor k in file_paths:\\n\\n  with open(k,\\'r\\') as f:\\n    reader = csv.reader(f)\\n    block = []\\n    tup = []\\n    for row in reader:\\n      if row == []:\\n        block.append(tup)\\n        tup = []\\n      else:\\n        if row[0]!=\\'\\':\\n          row.append(k)\\n          tup.append(list(row))\\n    clean_b = []\\n    for b in block:\\n      new_b = [ x for x in b if x[2] in [\\'PSG\\',\\'AMCS\\'] ]\\n      #print(new_b)\\n      if new_b!=[]:\\n        clean_b.append(new_b)\\n\\n    print(\"CLEAN B of \",k)\\n    for t in clean_b:\\n      print(t)\\n   # data.append(list(clean_b ))\\n\\n\\nmac = []\\nfor round in data:\\n  for reading in round:\\n    for signal in reading:\\n      #print(signal[0])\\n      mac.append(signal[0])\\nprint(set(mac))\\nmac = set(mac)\\n\\n\\nheader = list(mac)\\n\\n#header.append(\\'Room\\')\\n\\n\\nroom = {\\n    \"2011.txt\" : 201,\\n    \"2012.txt\" : 201,\\n    \"2021.txt\" : 202,\\n    \"2022.txt\" : 202,\\n    \"61.txt\" : 6,\\n    \"62.txt\" : 6,\\n    \"71.txt\" : 7,\\n    \\'72.txt\\' : 7,\\n    \\'81.txt\\' : 8,\\n    \\'82.txt\\' : 8\\n}\\n\\ndict_list = []\\n\\nfor k in file_paths:\\n  with open(k,\\'r\\') as f:\\n    reader = csv.reader(f)\\n    block = []\\n    tup = []\\n    for row in reader:\\n      if row == []:\\n        block.append(tup)\\n        tup = []\\n      else:\\n        if row[0]!=\\'\\':\\n          #row.append(room[k])\\n          tup.append(list(row))\\n    clean_b = []\\n    for b in block:\\n      new_b = [ x for x in b if x[2] in [\\'PSG\\',\\'AMCS\\'] ]\\n      #print(new_b)\\n      if new_b!=[]:\\n        clean_b.append(new_b)\\n\\n\\n    print(\"CLEAN B of \",k)\\n    for record in clean_b:\\n      base_dict = {\\n          \\'00:FC:BA:32:99:40\\'  :  0,\\n          \\'78:72:5D:DE:99:20\\'  :  0,\\n          \\'00:FC:BA:32:91:40\\'  :  0,\\n          \\'78:72:5D:F5:5F:10\\' :  0,\\n          \\'00:FC:BA:32:77:E0\\'  :  0,\\n          \\'00:35:1A:08:44:60\\'  :  0,\\n          \\'00:35:1A:08:46:10\\'  :  0,\\n          \\'00:FC:BA:32:9A:E0\\'  :  0,\\n          \\'00:24:B2:81:A9:A0\\'  :  0,\\n          \\'00:FC:BA:32:9A:80\\'  :  0,\\n          \\'00:FC:BA:32:98:E0\\'  :  0,\\n          #\\'Room\\': \\'\\'\\n      }\\n      for reading in record:\\n        base_dict[reading[0]] = reading[1]\\n        #base_dict[\\'Room\\'] = reading[-1]\\n      dict_list.append(base_dict)\\n\\n    for l in dict_list:\\n      print(l)\\n\\nwith open(\"data_test.csv\",\\'w\\') as op:\\n  w = csv.DictWriter(op,fieldnames=header)\\n  w.writeheader()\\n  w.writerows(dict_list)\\n\\nnd = pd.read_csv(\\'data_test.csv\\')\\n\\nfor i in range(len(nd)):\\n  knn.predict([nd.iloc[i]], columns = header)\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "\n",
        "file_paths = [\"2011.txt\", \"2012.txt\", \"2021.txt\", \"2022.txt\", \"61.txt\", \"62.txt\", \"71.txt\",'72.txt','81.txt','82.txt']\n",
        "data = []\n",
        "for k in file_paths:\n",
        "\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(k)\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      #print(new_b)\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "    # print(\"CLEAN B of \",k)\n",
        "    # for t in clean_b:\n",
        "    #   print(t)\n",
        "    data.append(list(clean_b ))\n",
        "\n",
        "\n",
        "mac = []\n",
        "for round in data:\n",
        "  for reading in round:\n",
        "    for signal in reading:\n",
        "      #print(signal[0])\n",
        "      mac.append(signal[0])\n",
        "# print(set(mac))\n",
        "mac = set(mac)\n",
        "\n",
        "\n",
        "header = list(mac)\n",
        "\n",
        "header.append('Room')\n",
        "\n",
        "\n",
        "room = {\n",
        "    \"2011.txt\" : 201,\n",
        "    \"2012.txt\" : 201,\n",
        "    \"2021.txt\" : 202,\n",
        "    \"2022.txt\" : 202,\n",
        "    \"61.txt\" : 6,\n",
        "    \"62.txt\" : 6,\n",
        "    \"71.txt\" : 7,\n",
        "    '72.txt' : 7,\n",
        "    '81.txt' : 8,\n",
        "    '82.txt' : 8\n",
        "}\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for k in file_paths:\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(room[k])\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      #print(new_b)\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "\n",
        "    #print(\"CLEAN B of \",k)\n",
        "    for record in clean_b:\n",
        "      base_dict = {\n",
        "          '00:FC:BA:32:99:40'  :  0,\n",
        "          '78:72:5D:DE:99:20'  :  0,\n",
        "          '00:FC:BA:32:91:40'  :  0,\n",
        "          '78:72:5D:F5:5F:10' :  0,\n",
        "          '00:FC:BA:32:77:E0'  :  0,\n",
        "          '00:35:1A:08:44:60'  :  0,\n",
        "          '00:35:1A:08:46:10'  :  0,\n",
        "          '00:FC:BA:32:9A:E0'  :  0,\n",
        "          '00:24:B2:81:A9:A0'  :  0,\n",
        "          '00:FC:BA:32:9A:80'  :  0,\n",
        "          '00:FC:BA:32:98:E0'  :  0,\n",
        "          'Room': ''\n",
        "      }\n",
        "      for reading in record:\n",
        "        base_dict[reading[0]] = reading[1]\n",
        "        base_dict['Room'] = reading[-1]\n",
        "      dict_list.append(base_dict)\n",
        "\n",
        "    # for l in dict_list:\n",
        "    #   print(l)\n",
        "\n",
        "with open(\"data_nuevo.csv\",'w') as op:\n",
        "  w = csv.DictWriter(op,fieldnames=header)\n",
        "  w.writeheader()\n",
        "  w.writerows(dict_list)\n",
        "\n",
        "#=======================================================================\n",
        "\n",
        "d = pd.read_csv(\"data_nuevo.csv\")\n",
        "#print(d.head())\n",
        "X = d.drop(['Room'], axis='columns').values\n",
        "y = d.Room.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.55, random_state=42)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "print(knn.score(X_test, y_test))\n",
        "\n",
        "'''\n",
        "import csv\n",
        "file_paths = [\"201.txt\"]\n",
        "#data = []\n",
        "for k in file_paths:\n",
        "\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(k)\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      #print(new_b)\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "    print(\"CLEAN B of \",k)\n",
        "    for t in clean_b:\n",
        "      print(t)\n",
        "   # data.append(list(clean_b ))\n",
        "\n",
        "\n",
        "mac = []\n",
        "for round in data:\n",
        "  for reading in round:\n",
        "    for signal in reading:\n",
        "      #print(signal[0])\n",
        "      mac.append(signal[0])\n",
        "print(set(mac))\n",
        "mac = set(mac)\n",
        "\n",
        "\n",
        "header = list(mac)\n",
        "\n",
        "#header.append('Room')\n",
        "\n",
        "\n",
        "room = {\n",
        "    \"2011.txt\" : 201,\n",
        "    \"2012.txt\" : 201,\n",
        "    \"2021.txt\" : 202,\n",
        "    \"2022.txt\" : 202,\n",
        "    \"61.txt\" : 6,\n",
        "    \"62.txt\" : 6,\n",
        "    \"71.txt\" : 7,\n",
        "    '72.txt' : 7,\n",
        "    '81.txt' : 8,\n",
        "    '82.txt' : 8\n",
        "}\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for k in file_paths:\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          #row.append(room[k])\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      #print(new_b)\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "\n",
        "    print(\"CLEAN B of \",k)\n",
        "    for record in clean_b:\n",
        "      base_dict = {\n",
        "          '00:FC:BA:32:99:40'  :  0,\n",
        "          '78:72:5D:DE:99:20'  :  0,\n",
        "          '00:FC:BA:32:91:40'  :  0,\n",
        "          '78:72:5D:F5:5F:10' :  0,\n",
        "          '00:FC:BA:32:77:E0'  :  0,\n",
        "          '00:35:1A:08:44:60'  :  0,\n",
        "          '00:35:1A:08:46:10'  :  0,\n",
        "          '00:FC:BA:32:9A:E0'  :  0,\n",
        "          '00:24:B2:81:A9:A0'  :  0,\n",
        "          '00:FC:BA:32:9A:80'  :  0,\n",
        "          '00:FC:BA:32:98:E0'  :  0,\n",
        "          #'Room': ''\n",
        "      }\n",
        "      for reading in record:\n",
        "        base_dict[reading[0]] = reading[1]\n",
        "        #base_dict['Room'] = reading[-1]\n",
        "      dict_list.append(base_dict)\n",
        "\n",
        "    for l in dict_list:\n",
        "      print(l)\n",
        "\n",
        "with open(\"data_test.csv\",'w') as op:\n",
        "  w = csv.DictWriter(op,fieldnames=header)\n",
        "  w.writeheader()\n",
        "  w.writerows(dict_list)\n",
        "\n",
        "nd = pd.read_csv('data_test.csv')\n",
        "\n",
        "for i in range(len(nd)):\n",
        "  knn.predict([nd.iloc[i]], columns = header)\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "file_paths = [\"201.txt\"]\n",
        "#data = []\n",
        "for k in file_paths:\n",
        "\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(k)\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      #print(new_b)\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "    # print(\"CLEAN B of \",k)\n",
        "    # for t in clean_b:\n",
        "    #   print(t)\n",
        "   # data.append(list(clean_b ))\n",
        "\n",
        "\n",
        "mac = []\n",
        "for round in data:\n",
        "  for reading in round:\n",
        "    for signal in reading:\n",
        "      #print(signal[0])\n",
        "      mac.append(signal[0])\n",
        "print(set(mac))\n",
        "mac = set(mac)\n",
        "\n",
        "\n",
        "header = list(mac)\n",
        "\n",
        "#header.append('Room')\n",
        "\n",
        "\n",
        "room = {\n",
        "    \"2011.txt\" : 201,\n",
        "    \"2012.txt\" : 201,\n",
        "    \"2021.txt\" : 202,\n",
        "    \"2022.txt\" : 202,\n",
        "    \"61.txt\" : 6,\n",
        "    \"62.txt\" : 6,\n",
        "    \"71.txt\" : 7,\n",
        "    '72.txt' : 7,\n",
        "    '81.txt' : 8,\n",
        "    '82.txt' : 8\n",
        "}\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for k in file_paths:\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          #row.append(room[k])\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      #print(new_b)\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "\n",
        "    #print(\"CLEAN B of \",k)\n",
        "    for record in clean_b:\n",
        "      base_dict = {\n",
        "          '00:FC:BA:32:99:40'  :  0,\n",
        "          '78:72:5D:DE:99:20'  :  0,\n",
        "          '00:FC:BA:32:91:40'  :  0,\n",
        "          '78:72:5D:F5:5F:10' :  0,\n",
        "          '00:FC:BA:32:77:E0'  :  0,\n",
        "          '00:35:1A:08:44:60'  :  0,\n",
        "          '00:35:1A:08:46:10'  :  0,\n",
        "          '00:FC:BA:32:9A:E0'  :  0,\n",
        "          '00:24:B2:81:A9:A0'  :  0,\n",
        "          '00:FC:BA:32:9A:80'  :  0,\n",
        "          '00:FC:BA:32:98:E0'  :  0,\n",
        "          #'Room': ''\n",
        "      }\n",
        "      for reading in record:\n",
        "        base_dict[reading[0]] = reading[1]\n",
        "        #base_dict['Room'] = reading[-1]\n",
        "      dict_list.append(base_dict)\n",
        "\n",
        "    # for l in dict_list:\n",
        "    #   print(l)\n",
        "\n",
        "with open(\"data_test.csv\",'w') as op:\n",
        "  w = csv.DictWriter(op,fieldnames=header)\n",
        "  w.writeheader()\n",
        "  w.writerows(dict_list)\n",
        "\n",
        "nd = pd.read_csv('data_test.csv')\n",
        "\n",
        "nd\n",
        "\n",
        "for k,v in nd.iterrows():\n",
        "  #print(v)\n",
        "  #array = np.array(v)\n",
        "  #print(array)\n",
        "  ans = knn.predict(array.reshape(1,-1))\n",
        "  print(ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2m5rQdTv_B",
        "outputId": "3d43d933-4aa7-48e3-f82c-404606e3c29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'78:72:5D:F5:5F:10', '00:FC:BA:32:9A:80', '78:72:5D:DE:99:20', '00:FC:BA:32:91:40', '00:24:B2:81:A9:A0', '00:FC:BA:32:77:E0', '00:35:1A:08:44:60', '00:35:1A:08:46:10', '00:FC:BA:32:99:40', '00:FC:BA:32:98:E0', '00:FC:BA:32:9A:E0'}\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n",
            "[201]\n"
          ]
        }
      ]
    }
  ]
}