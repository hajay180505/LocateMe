{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvfXCqD+04TV6p0jhuvb84",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hajay180505/LocateMe/blob/main/NuevoLocateMe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning github repo for the dataset source files"
      ],
      "metadata": {
        "id": "p5k1yAnSSes-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hajay180505/LocateMe.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVEBhE51-4n1",
        "outputId": "02c228c5-0193-4fbd-f746-3297ca96c87c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LocateMe' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Imports:\n",
        "> * **csv** - for creating a csv data file from the read data \\\\\n",
        "> * **pandas** - to create a dataframe for the dataset in order to train it\n",
        ">*  **numpy** - for data handling processes\n",
        ">* **train_test_split** - for splitting testing and training data\n",
        ">* **K NeighborsClassifier** - the ML model used\n",
        ">* **accuracy_score** - for measuring the accuracy of the model\n",
        ">* **joblib** - for exporting the model\n",
        ">* **stats** - for using mode of a _NumPy_ array"
      ],
      "metadata": {
        "id": "xb_mfed3vdgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "\n",
        "from scipy import stats as st\n"
      ],
      "metadata": {
        "id": "Leh_e6Rcva0d"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Room mapping for the text files in the data"
      ],
      "metadata": {
        "id": "d7T29u2JRJUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "room = {\n",
        "    \"2011.txt\" : 201,\n",
        "    \"2012.txt\" : 201,\n",
        "    \"2021.txt\" : 202,\n",
        "    \"2022.txt\" : 202,\n",
        "    \"61.txt\" : 6,\n",
        "    \"62.txt\" : 6,\n",
        "    \"71.txt\" : 7,\n",
        "    '72.txt' : 7,\n",
        "    '81.txt' : 8,\n",
        "    '82.txt' : 8\n",
        "}"
      ],
      "metadata": {
        "id": "xIz00rZBNWs7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing the data:\n",
        "  The collected data from RPI is parsed to make it into a single csv file."
      ],
      "metadata": {
        "id": "xEbWskKe67lg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1KSTW9sgPJaA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "file_paths = [\"2011.txt\", \"2012.txt\", \"2021.txt\", \"2022.txt\", \"61.txt\", \"62.txt\", \"71.txt\",'72.txt','81.txt','82.txt']\n",
        "data = []\n",
        "final_file = input(\"Enter final data file name with extension(.csv) :\")\n",
        "for k in file_paths:\n",
        "\n",
        "  with open('LocateMe/Wifi_data/' + k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(k)\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "    data.append(list(clean_b ))\n",
        "\n",
        "\n",
        "mac = []\n",
        "for round in data:\n",
        "  for reading in round:\n",
        "    for signal in reading:\n",
        "      mac.append(signal[0])\n",
        "mac = set(mac)\n",
        "\n",
        "\n",
        "header = list(mac)\n",
        "\n",
        "header.append('Room')\n",
        "\n",
        "\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for k in file_paths:\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(room[k])\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "    for record in clean_b:\n",
        "      base_dict = {\n",
        "          '00:FC:BA:32:99:40'  :  0,\n",
        "          '78:72:5D:DE:99:20'  :  0,\n",
        "          '00:FC:BA:32:91:40'  :  0,\n",
        "          '78:72:5D:F5:5F:10' :  0,\n",
        "          '00:FC:BA:32:77:E0'  :  0,\n",
        "          '00:35:1A:08:44:60'  :  0,\n",
        "          '00:35:1A:08:46:10'  :  0,\n",
        "          '00:FC:BA:32:9A:E0'  :  0,\n",
        "          '00:24:B2:81:A9:A0'  :  0,\n",
        "          '00:FC:BA:32:9A:80'  :  0,\n",
        "          '00:FC:BA:32:98:E0'  :  0,\n",
        "          'Room': ''\n",
        "      }\n",
        "      for reading in record:\n",
        "        base_dict[reading[0]] = reading[1]\n",
        "        base_dict['Room'] = reading[-1]\n",
        "      dict_list.append(base_dict)\n",
        "\n",
        "\n",
        "with open(final_file,'w') as op:\n",
        "  w = csv.DictWriter(op,fieldnames=header)\n",
        "  w.writeheader()\n",
        "  w.writerows(dict_list)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating K Neighbors Classifier with `n_neighbors = 5` and testing its accuracy"
      ],
      "metadata": {
        "id": "HzjO6sYyRsI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.read_csv(final_file)\n",
        "\n",
        "X = d.drop(['Room'], axis='columns').values\n",
        "y = d.Room.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.55, random_state=42)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "print(knn.score(X_test, y_test))\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_hnS2o4Lr2T",
        "outputId": "04d0c6a4-ff1d-45bb-d897-266e0e60b4d0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9391634980988594\n",
            "0.9391634980988594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = input(\"Enter the model name with .pkl extension :\")\n",
        "\n",
        "joblib.dump(knn, model_file)\n",
        "\n",
        "# # Load the model from the file\n",
        "# knn_from_joblib = joblib.load('model.pkl')\n",
        "\n",
        "# # Use the loaded model to make predictions\n",
        "# knn_from_joblib.predict(X_test)\n",
        "# print(knn_from_joblib.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8scyA0dL1zu",
        "outputId": "269c6d11-b8fb-4940-aae4-77d0e1b41c65"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using  the created knn model to predict a location from a new data source"
      ],
      "metadata": {
        "id": "9fIOp6bDSMFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "file_paths = [\"201.txt\"]\n",
        "#data = []\n",
        "\n",
        "knn_from_joblib = joblib.load(model_file)\n",
        "\n",
        "\n",
        "for k in file_paths:\n",
        "\n",
        "  with open('LocateMe/Wifi_data/'+ k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          row.append(k)\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "\n",
        "mac = []\n",
        "for round in data:\n",
        "  for reading in round:\n",
        "    for signal in reading:\n",
        "      mac.append(signal[0])\n",
        "\n",
        "\n",
        "#print(set(mac))\n",
        "\n",
        "mac = set(mac)\n",
        "\n",
        "\n",
        "header = list(mac)\n",
        "\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for k in file_paths:\n",
        "  with open(k,'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    block = []\n",
        "    tup = []\n",
        "    for row in reader:\n",
        "      if row == []:\n",
        "        block.append(tup)\n",
        "        tup = []\n",
        "      else:\n",
        "        if row[0]!='':\n",
        "          tup.append(list(row))\n",
        "    clean_b = []\n",
        "    for b in block:\n",
        "      new_b = [ x for x in b if x[2] in ['PSG','AMCS'] ]\n",
        "      if new_b!=[]:\n",
        "        clean_b.append(new_b)\n",
        "\n",
        "    for record in clean_b:\n",
        "      base_dict = {\n",
        "          '00:FC:BA:32:99:40'  :  0,\n",
        "          '78:72:5D:DE:99:20'  :  0,\n",
        "          '00:FC:BA:32:91:40'  :  0,\n",
        "          '78:72:5D:F5:5F:10'  :  0,\n",
        "          '00:FC:BA:32:77:E0'  :  0,\n",
        "          '00:35:1A:08:44:60'  :  0,\n",
        "          '00:35:1A:08:46:10'  :  0,\n",
        "          '00:FC:BA:32:9A:E0'  :  0,\n",
        "          '00:24:B2:81:A9:A0'  :  0,\n",
        "          '00:FC:BA:32:9A:80'  :  0,\n",
        "          '00:FC:BA:32:98:E0'  :  0,\n",
        "          #'Room': ''\n",
        "      }\n",
        "      for reading in record:\n",
        "        base_dict[reading[0]] = reading[1]\n",
        "      dict_list.append(base_dict)\n",
        "\n",
        "with open(\"data_test.csv\",'w') as op:\n",
        "  w = csv.DictWriter(op,fieldnames=header)\n",
        "  w.writeheader()\n",
        "  w.writerows(dict_list)\n",
        "\n",
        "nd = pd.read_csv('data_test.csv')\n",
        "\n",
        "whole = knn.predict(np.array(nd))\n",
        "\n",
        "print(\"Whole :\",whole)\n",
        "\n",
        "# for k,v in nd.iterrows():\n",
        "#   #print(v)\n",
        "#   array = np.array(v)\n",
        "#   #print(array)\n",
        "#   ans = knn_from_joblib.predict(array.reshape(1,-1))\n",
        "#   print(ans)\n",
        "\n",
        "print(\"Location most likely is\", st.mode(whole).mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2m5rQdTv_B",
        "outputId": "9bc98162-74c3-46de-c897-f378756ae088"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole : [201 202 202 202 202 201 201 201 201 201 201 201 201 201 201]\n",
            "Location most likely is 201\n"
          ]
        }
      ]
    }
  ]
}